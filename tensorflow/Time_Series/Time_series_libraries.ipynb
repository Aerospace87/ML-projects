{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRwgiUjaxxdXm0ql5WLQIw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aerospace87/ML-projects/blob/main/tensorflow/Time_Series/Time_series_libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving Average Derivation\n",
        "\n",
        "Suppose we have a time series:\n",
        "\n",
        "\\begin{align}\n",
        "x_t \\hspace{2cm} t=0,1,..,T-1\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "And its cumulative sum:\n",
        "\n",
        "\\begin{align}\n",
        "c_t = \\sum_{i=0}^t x_i\n",
        "\\end{align}\n",
        "\n",
        "And we want to compute the moving average at time step $t$, by considering the $w$ previous time steps ($t$ is also included):\n",
        "\n",
        "\\begin{align}\n",
        "\\overline{x}_t = \\frac{1}{w} \\sum_{i = t-w+1}^t x_i \\hspace{2cm} \\, for \\, t = w-1,...,T-1.\n",
        "\\end{align}\n",
        "\n",
        "The cumulative sum at time $t$ can be written as:\n",
        "\n",
        "\\begin{align}\n",
        "c_t = \\sum_{i=0}^t x_i = \\sum_{i=0}^{t-w} x_i \\, + \\, \\sum_{i=t-w+1}^{t} x_i = c_{t-w} \\, + \\, w\\, \\overline{x}_t\n",
        "\\end{align}\n",
        "\n",
        "The previous formula is defined for $t=w,...,T-1$ as can be seen by inspecting the upper extreme of the first sum and considering that $x_t$ is definited for $t\\ge0$, therefore:\n",
        "\n",
        "\\begin{align}\n",
        "\\overline{x}_t = \\frac{1}{w}(c_t - c_{t-w}) \\hspace{2cm} t=w,...,T-1.\n",
        "\\end{align}\n",
        "\n",
        "To find $\\overline{x}_t$ at time $t=w-1$ we use the definition:\n",
        "\n",
        "\\begin{align}\n",
        "\\overline{x}_{w-1} = \\frac{1}{w} \\sum_{i = (w-1)-w+1}^{w-1} x_i = \\frac{1}{w} \\sum_{i = 0}^{w-1} x_i = \\frac{1}{w} c_{w-1}.\n",
        "\\end{align}\n",
        "\n",
        "Overall, the moving average can be computed via:\n",
        "\n",
        "\\begin{cases}\n",
        "      \\overline{x}_{w-1} = \\frac{1}{w} c_{w-1}\\\\\n",
        "      \\overline{x}_t = \\frac{1}{w}(c_t - c_{t-w}) \\hspace{2cm} t=w,...,T-1.\n",
        "\\end{cases}\n",
        "\n",
        "### Algorithm definition\n",
        "\n",
        "If we want to use a unique array called mov we can implement the following algorithm:\n",
        "\n",
        "1. Define variable **mov** as the cumulative average.\n",
        "2. Modify the elemnts of the array mov from the index $w$ by using\n",
        "   the difference:\n",
        "   \n",
        "   **mov[w:] = mov[w:] - mov[:-w]**\n",
        "\n",
        "3. Note that mov[w-1] has still the initial value equal to the\n",
        "   cumulative sum at $t=w-1$ therefore we return the array:\n",
        "\n",
        "   **(1/w)  mov[w-1:]**\n",
        "\n",
        "\n",
        "This algorithm is implemented in the function moving_average_forecast:"
      ],
      "metadata": {
        "id": "JrG3Uqm7GdUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_average_forecast(series, window_size):\n",
        "  \"\"\"Forecasts the mean of the last few values.\n",
        "     If window_size=1, then this is equivalent to naive forecast\n",
        "     This implementation is *much* faster than the previous one\"\"\"\n",
        "  mov = np.cumsum(series)\n",
        "\n",
        "  # This is necessary because to subtract two pandas series it is necessary\n",
        "  # That both series have the same index. Therefore we force the series\n",
        "  # mov[window_size:] and mov[:-window_size] to have the same index\n",
        "\n",
        "  index = pd.Index(\n",
        "      list(\n",
        "          range(mov.size - window_size)\n",
        "      )\n",
        "  )\n",
        "\n",
        "  mov[window_size:] = mov[window_size:].set_axis(index)- mov[:-window_size].set_axis(index)\n",
        "\n",
        "  return mov[window_size - 1:] / window_size"
      ],
      "metadata": {
        "id": "EEa_Kdn8GzbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Difference\n",
        "\n",
        "The first difference is defined as:\n",
        "$d_t = x_t - x_{t-q} \\hspace{2cm} t=q,..., T-1$\n",
        "\n",
        "Therefore it can be implemenentate in the function diff_series following the algoritm:\n",
        "\n",
        "1. Define the original series as the variable **series**\n",
        "\n",
        "2. Return the difference **series[q:] - series[:-q]**"
      ],
      "metadata": {
        "id": "k2ItphhAG8n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diff_series(series, q):\n",
        "  original_index = series.index.copy()\n",
        "\n",
        "  # saving te first q values in cae we want to recnstruct te original\n",
        "  # series\n",
        "  first_q_values = series[:q].to_numpy(copy=True)\n",
        "\n",
        "  # Removal of the first t0-1 indices\n",
        "  original_index = original_index.delete(list(range(q)))\n",
        "\n",
        "  # conversion into numpy array to avoid indices mismatches\n",
        "  series = series[q:].to_numpy(copy=True) - series[:-q].to_numpy(copy=True)\n",
        "\n",
        "  # Returning the final pandas series from the previous numpy array\n",
        "  return pd.Series(series, index=original_index), first_q_values, original_index"
      ],
      "metadata": {
        "id": "-4741NzIG_dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Series Integration\n",
        "\n",
        "In order to reconstruct the original series from the differenced one we consider the first difference written for te first term of te original series as:\n",
        "\n",
        "$x_{t_0+q}=  x_{t_0} + d_{t_0+q} \\hspace{1cm} t_0=0, ...,q-1$\n",
        "\n",
        "$x_{t_0+2q}=  x_{t_0 + q} + d_{t_0+2q} \\hspace{1cm} t_0=0, ...,q-1$\n",
        "\n",
        "Therefore:\n",
        "\n",
        "$x_{t_0+2q}=  x_{t_0} + d_{t_0+q} + d_{t_0+2q} \\hspace{1cm} t_0=0, ...,q-1$\n",
        "\n",
        "Reasoning by induction we find then:\n",
        "\n",
        "$x_{t_0+nq}=  x_{t_0} + \\sum_{k=1}^n d_{t_0+kq}  \\hspace{1cm} t_0=0, ...,q-1$\n",
        "\n",
        "if we definw the $q$ subseries:\n",
        "\n",
        "$d^0 = d_{t_0 + kq}  \\hspace{1cm} k=1,...,n$ we apply cumulative sum and add $x_{t_0}$ we find the subseries $x_{t_0+nq}$. All the $q$ subseries (obtained by changing $t_0$) can be then used to reconstruct the full original series $x_t$.\n"
      ],
      "metadata": {
        "id": "fH7Y0OB-HIfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def integrate_series(first_q_values, series):\n",
        "\n",
        "  \"\"\"Function to reconstruct a differenced time series given the first\n",
        "     q  values of the original series\"\"\"\n",
        "\n",
        "  original_index = series.index\n",
        "\n",
        "  q = first_q_values.size\n",
        "  T = series.size\n",
        "\n",
        "  # Creation of an annay of zeros with the final size of the time series\n",
        "  result = np.zeros(shape= T)\n",
        "\n",
        "  # Restablishing the first q values of the original series\n",
        "  result[:q] = first_q_values\n",
        "\n",
        "  # Creation of the q subseries\n",
        "  for t0 in range(q):\n",
        "    sub_series = series[t0+q::q].to_numpy()\n",
        "\n",
        "    sub_series = first_q_values[t0] + np.cumsum(sub_series)\n",
        "\n",
        "    # Population of the subseries\n",
        "    for k in range(len(sub_series)):\n",
        "      result[t0 + (k+1)*q] = sub_series[k]\n",
        "\n",
        "  return pd.Series(result, index = original_index)"
      ],
      "metadata": {
        "id": "qlEe7-OeHLq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fourier Transform\n",
        "Fourier transform and Power Spectral Density (PSD) are used to find seasonality in the timeseries. The frequencies of seasonality may be identifying by peaks in the PSD.\n"
      ],
      "metadata": {
        "id": "Zfd0fylsHYiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_fft(series):\n",
        "  \"\"\"Function to compute the fft of an array\"\"\"\n",
        "\n",
        "  N = series.size\n",
        "\n",
        "  # Frequencies in cycles/delta_t. Only the positive frequencies are taken\n",
        "  # because the function is real and the FFT is symmetric\n",
        "  frequencies = fftfreq(N, d = 1)[:N//2]\n",
        "\n",
        "  # Discrete Fourier Transform computation. Only te values with Re[ft] >= 0 are taken\n",
        "  return fft(series)[:N//2], frequencies"
      ],
      "metadata": {
        "id": "N86MdUJsQzb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.fft import fft, ifft\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_psd(series, batch_size, max_freq_to_plot=None, scale =\"linear\"):\n",
        "  \"\"\"Function to compute the PSD for each batch and then average resulting PSDs to\n",
        "  remove noise. Please note that the peak are meant to occur ar te index of the series\n",
        "  and not frequency. For example:\n",
        "  x = np.linspace(0.0,1.0, 10000)\n",
        "  y = np.sin(2.0*np.pi*x) give a peak for the first index\"\"\"\n",
        "\n",
        "  number_batches = series.size // batch_size\n",
        "\n",
        "  psd = np.zeros(batch_size // 2)\n",
        "\n",
        "  for ii in range(number_batches):\n",
        "    batch = series[ii*batch_size: (ii+1)*(batch_size)]\n",
        "\n",
        "    batch_fft, freq = compute_fft(batch)\n",
        "\n",
        "    psd += np.square(np.abs(batch_fft))\n",
        "\n",
        "  max_frequency = np.max(freq)\n",
        "\n",
        "  if max_freq_to_plot is not None:\n",
        "    plt.xlim(-0.005,max_freq_to_plot)\n",
        "  else:\n",
        "    plt.xlim(-0.005,max_frequency)\n",
        "\n",
        "  plt.yscale(scale)\n",
        "  plt.plot(freq, psd)"
      ],
      "metadata": {
        "id": "LewUWCNTQ99B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "def check_stationary(series, significance=0.05):\n",
        "\n",
        "  \"\"\" Function to check the stationarity of a series with Dickey Fuller Test\"\"\"\n",
        "  ADF = adfuller(series, regression = 'n')\n",
        "  test_statistic = ADF[0]\n",
        "  p_value = ADF[1]\n",
        "\n",
        "  if p_value < significance:\n",
        "    msg = \"The series is stationary because there is not unit root in the series \"\n",
        "    msg += f\"\\nbased on a significance of {significance*100}% (Alternate Hypothesis).\"\n",
        "    print(msg)\n",
        "  else:\n",
        "    print(\"The series is not stationary.\")"
      ],
      "metadata": {
        "id": "CIj7cLRyU7oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
        "\n",
        "def plot_PACF(series, confidence=0.95, lags=40, fig_width=12, fig_height=6, xmin=0, xmax=40 , ymin=-1, ymax=1):\n",
        "\n",
        "  \"\"\"Function to plot the partial autcorrelation function\"\"\"\n",
        "  plt.figure(figsize=(fig_width, fig_height))\n",
        "  plot_pacf(series, lags=lags, alpha = 1.0 - confidence)\n",
        "  plt.xlabel('lag')\n",
        "  plt.ylabel('PACF')\n",
        "  plt.xlim(xmin, xmax)\n",
        "  plt.ylim(ymin, ymax)\n",
        "  plt.show()\n",
        "\n",
        "def plot_ACF(series, confidence=0.95, lags=40, fig_width=12, fig_height=6, xmin=0, xmax=40 , ymin=-1, ymax=1):\n",
        "\n",
        "  \"\"\"Function to plot the autcorrelation function\"\"\"\n",
        "  plt.figure(figsize=(fig_width, fig_height))\n",
        "  plot_acf(series, lags=lags, alpha = 1.0 - confidence)\n",
        "  plt.xlabel('lag')\n",
        "  plt.ylabel('ACF')\n",
        "  plt.xlim(xmin, xmax)\n",
        "  plt.ylim(ymin, ymax)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fcS3gpZTVk7X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}